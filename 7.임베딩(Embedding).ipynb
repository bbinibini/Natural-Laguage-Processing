{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 임베딩(Embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 워드 임베딩은 단어를 컴퓨터가 이해하고, 효율적으로 처리할 수 있도록 `단어를 벡터화`하는 기술\n",
    "* 워드 임베딩은 단어의 의미를 잘 표현해야만 하며, 현재까지도 많은 표현 방법이 연구\n",
    "* 워드 임베딩을 거쳐 잘 표현된 단어 벡터들은 `계산이 가능`하며, `모델 투입`도 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인코딩(Encoding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 기계는 자연어(영어, 한국어 등)을 이해할 수 없음\n",
    "* 데이터를 기계가 이해할 수 있도록 `숫자 등으로 변환`해주는 작업이 필요\n",
    "* 이러한 작업을 인코딩이라고 함\n",
    "* 텍스트 처리에서는 주로 `정수 인코딩`, `원 핫 인코딩`을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정수 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  dictionary를 이용한 정수 인코딩\n",
    "* 각 단어와 정수 인덱스를 연결하고, 토큰을 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['평생', '그리고', '꾸어라.', '죽을', '살', '살아라', '오늘을', '내일', '것처럼', '꿈을']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"평생 살 것처럼 꿈을 꾸어라. 그리고 내일 죽을 것처럼 오늘을 살아라\"\n",
    "\n",
    "#tokenize 한다음에 중복되지 않도록 list로 만들어줌\n",
    "tokens = [x for x in text.split(' ')]\n",
    "unique = set(tokens)\n",
    "unique = list(unique)\n",
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'평생': 0,\n",
       " '그리고': 1,\n",
       " '꾸어라.': 2,\n",
       " '죽을': 3,\n",
       " '살': 4,\n",
       " '살아라': 5,\n",
       " '오늘을': 6,\n",
       " '내일': 7,\n",
       " '것처럼': 8,\n",
       " '꿈을': 9}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unique한 것에 index를 넣어줌\n",
    "token2idx = {}\n",
    "for i in range(len(unique)) :\n",
    "    token2idx[unique[i]] = i\n",
    "\n",
    "token2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 8, 9, 2, 1, 7, 3, 8, 6, 5]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# token에 대해서 encoding한 것 출력\n",
    "encode = [token2idx[x] for x in tokens]\n",
    "encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keras를 이용한 정수 인코딩\n",
    "* 단어에 정수로 레이블을 부여\n",
    "* dictionary, nltk패키지를 이용한 방법들도 있지만, keras에서는 텍스트 처리에 필요한 도구들을 지원\n",
    "* 해당 도구는 자동으로 `단어 빈도가 높은 단어의 인덱스는 낮게`끔 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'것처럼': 1, '평생': 2, '살': 3, '꿈을': 4, '꾸어라': 5, '그리고': 6, '내일': 7, '죽을': 8, '오늘을': 9, '살아라': 10}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "text = \"평생 살 것처럼 꿈을 꾸어라. 그리고 내일 죽을 것처럼 오늘을 살아라\"\n",
    "\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts([text])\n",
    "print(t.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 1, 4, 5, 6, 7, 8, 1, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "encoded = t.texts_to_sequences([text])[0]\n",
    "print(encoded)\n",
    "#인코딩된 결과 - 평생 / 살 / 것처럼 -> 2 3 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원 핫 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 조건문과 반복문을 이용한 원 핫 인코딩\n",
    "* 원 핫 인코딩은 `정수 인코딩한 결과를 벡터로 변환`한 인코딩\n",
    "* 원 핫 인코딩은 전체 단어 개수 만큼의 길이를 가진 배열에 해당 정수를 가진 위치는 1, 나머지는 0을 가진 벡터로 변환   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 1, 4, 5, 6, 7, 8, 1, 9, 10]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#정수 인코딩한 결과\n",
    "#text = \"평생 살 것처럼 꿈을 꾸어라. 그리고 내일 죽을 것처럼 오늘을 살아라\"\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "one_hot = []\n",
    "for i in range(len(encoded)) : #0~10 -> 길이는 11\n",
    "    temp = []\n",
    "    for j in range(max(encoded)) : #0~9 ->단어는 10개\n",
    "        if j == (encoded[i]-1): #현재단어와같다\n",
    "            temp.append(1)\n",
    "        else :\n",
    "            temp.append(0)\n",
    "    #같은 경우에만 1이 들어감.\n",
    "    one_hot.append(temp)\n",
    "\n",
    "np.array(one_hot)\n",
    "#one_hot 단어하나하나임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kears를 이용한 원 핫 인코딩\n",
    "* `keras`에서는 정수 인코딩을 원 핫 인코딩을 간단하게 변환해주는 `to_categorical()` 함수를 제공 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "one_hot = to_categorical(encoded)\n",
    "one_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
