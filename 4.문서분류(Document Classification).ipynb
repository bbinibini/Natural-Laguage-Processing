{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문서 분류(Document Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비\n",
    "* 문서 분류에 필요한 데이터는 scikit-learn이 제공하는 20개의 주제를 가지는 뉴스그룹 데이터를 사용\n",
    "* 텍스트는 CounterVectorizer를 거쳐 DTM으로 변환\n",
    "* DTM은문서에 등장하는 단어들을 빈도 수 별로 표현한 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "news = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\",\n",
       " \"From: guykuo@carson.u.washington.edu (Guy Kuo)\\nSubject: SI Clock Poll - Final Call\\nSummary: Final call for SI clock reports\\nKeywords: SI,acceleration,clock,upgrade\\nArticle-I.D.: shelley.1qvfo9INNc3s\\nOrganization: University of Washington\\nLines: 11\\nNNTP-Posting-Host: carson.u.washington.edu\\n\\nA fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.\\n\\nGuy Kuo <guykuo@u.washington.edu>\\n\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7919, 130107) (7919,) (3395, 130107) (3395,)\n"
     ]
    }
   ],
   "source": [
    "x = news.data\n",
    "y = news.target\n",
    "\n",
    "cv = CountVectorizer()\n",
    "x = cv.fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3)\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 56979)\t2\n",
      "  (0, 85354)\t2\n",
      "  (0, 114688)\t1\n",
      "  (0, 111322)\t1\n",
      "  (0, 68532)\t1\n",
      "  (0, 114731)\t1\n",
      "  (0, 90379)\t1\n",
      "  (0, 76032)\t1\n",
      "  (0, 114579)\t1\n",
      "  (0, 114455)\t2\n",
      "  (0, 115475)\t1\n",
      "  (0, 32311)\t1\n",
      "  (0, 66608)\t3\n",
      "  (0, 27436)\t1\n",
      "  (0, 37565)\t1\n",
      "  (0, 128402)\t1\n",
      "  (0, 62221)\t1\n",
      "  (0, 29573)\t1\n",
      "  (0, 124616)\t1\n",
      "  (0, 28146)\t2\n",
      "  (0, 124332)\t1\n",
      "  (0, 26605)\t1\n",
      "  (0, 29620)\t1\n",
      "  (0, 80010)\t2\n",
      "  (0, 28012)\t1\n",
      "  :\t:\n",
      "  (0, 58500)\t1\n",
      "  (0, 49336)\t1\n",
      "  (0, 82571)\t1\n",
      "  (0, 111911)\t1\n",
      "  (0, 68157)\t1\n",
      "  (0, 81124)\t1\n",
      "  (0, 93463)\t1\n",
      "  (0, 72413)\t1\n",
      "  (0, 94913)\t1\n",
      "  (0, 22211)\t1\n",
      "  (0, 114804)\t1\n",
      "  (0, 81207)\t1\n",
      "  (0, 106554)\t1\n",
      "  (0, 77294)\t1\n",
      "  (0, 113650)\t2\n",
      "  (0, 70356)\t1\n",
      "  (0, 94583)\t1\n",
      "  (0, 83445)\t1\n",
      "  (0, 4745)\t1\n",
      "  (0, 19280)\t1\n",
      "  (0, 31460)\t1\n",
      "  (0, 125105)\t1\n",
      "  (0, 83641)\t1\n",
      "  (0, 32720)\t1\n",
      "  (0, 70068)\t1\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0]) #0번째 문서에서 , 56979 인덱스 단어가 2번 등장했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learn을 이용한 문서 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "* 이중분류모델\n",
    "* Logistic Regression은 특성상 다중 분류에는 적합하지 않음\n",
    "* 선형 회귀 모델에 시그모이드 함수를 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8966126656848307\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression(solver='liblinear')\n",
    "LR.fit(x_train, y_train)\n",
    "pred = LR.predict(x_test)\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines\n",
    "* 회귀, 분류, 이상치 탐지 등에 사용되는 지도학습 방법\n",
    "* 클래스 사이의 경계에 위치한 데이터 포인트를 서포트 벡터(support vector)라고 함\n",
    "* 각 서포트 벡터가 클래스 사이의 결정 경계를 구분하는데 얼마나 중요한지를 학습\n",
    "* 각 서포트 벡터 사이의 마진이 가장 큰 방향으로 학습\n",
    "* 서포트 벡터까지의 거리와 서포트 벡터의 중요도를 기반으로 예측을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8282768777614139\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "SVM = svm.SVC(kernel='linear')\n",
    "SVM.fit(x_train, y_train)\n",
    "\n",
    "pred = SVM.predict(x_test)\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classification\n",
    "* 베이즈 정리를 적용한 확률적 분류 알고리즘\n",
    "* 모든 특성들이 독립임을 가정(naive 가정)\n",
    "* 입력 특성에 따라 3개의 분류기 존재\n",
    "    * 가우시안 나이브 베이즈 분류기\n",
    "    * 베르누이 나이브 베이즈 분류기\n",
    "    * 다항 나이브 베이즈 분류기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DTM을 이용한 나이브 베이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8244477172312223\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB = MultinomialNB()\n",
    "NB.fit(x_train, y_train)\n",
    "pred = NB.predict(x_test)\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf_idf를 이용한 정확도 향상 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TF-IDF(Term Frequency - Inverse Document Frequency)` 란?  \n",
    "* TF(단어 빈도, term frequency)는 특정한 단어가 문서 내에 얼마나 자주 등장하는지를 나타내는 값. \n",
    "* 이 값이 높을수록 문서에서 중요하다고 생각할 수 있다.\n",
    "* 하지만 하나의 문서에서 많이 나오지 않고 다른 문서에서 자주 등장하면 단어의 중요도는 낮아진다.\n",
    "* DF(문서 빈도, document frequency)라고 하며, 이 값의 역수를 IDF(역문서 빈도, inverse document frequency)라고 한다.\n",
    "* TF-IDF는 TF와 IDF를 곱한 값으로 점수가 높은 단어일수록 `다른 문서에는 많지 않고 해당 문서에서 자주 등장하는 단어`를 의미."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8332842415316642\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "x_train_tf = tfidf.fit_transform(x_train)\n",
    "x_test_tf = tfidf.fit_transform(x_test)\n",
    "\n",
    "NB.fit(x_train_tf, y_train)\n",
    "pred = NB.predict(x_test_tf)\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "* 분류나 회귀에 사용되는 지도 학습 방법\n",
    "* 데이터 특성으로부터 추론된 결정 `규칙`을 통해 값을 예측\n",
    "* if-then-else 결정 규칙을 통해 데이터 학습\n",
    "* 트리의 깊이가 깊을수록 복잡한 모델"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 스무고개 하듯이 예/아니오 질문을 이어가며 학습\n",
    "* 한번의 분기 때마다 변수 영역을 두 개로 구분합니다\n",
    "* 나뉜 각 범주에서 또 다시 데이터를 가장 잘 구분할 수 있는 질문을 기준으로 나눕니다. 이를 지나치게 많이 하면 오버피팅이 됩니다. 결정 트리에 아무 파라미터를 주지 않고 모델링하면 오버피팅이 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6382916053019145\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(x_train, y_train)\n",
    "pred = DT.predict(x_test)\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print(acc)\n",
    "# 현재 데이터로는 규칙을 찾기가 어려워서 정확도가 떨어짐.\n",
    "# 데이터 자체가 document, index라서. index만으로는 규칙을 찾기가 어려움.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "* XGBoost는 여러개의 Decision Tree를 조합해서 사용하는 Ensemble 알고리즘이다.\n",
    "* 분류에 있어서 다른 알고리즘보다 좋은 예측 성능을 보여줌\n",
    "\n",
    "* Boosting\n",
    "    * 약한 예측 모형들의 학습 에러에 가중치를 두고, 순차적으로 다음 학습 모델에 반영\n",
    "* Boosting 기법을 이용하여 구현한 알고리즘은 Gradient Boost 가 대표적인데\n",
    "* 이 알고리즘을 병렬 학습이 지원되도록 구현한 라이브러리가 XGBoost 이다.\n",
    "\n",
    "* 장점\n",
    "    * GBM 대비 빠른 수행시간\n",
    "병렬 처리로 학습, 분류 속도가 빠르다.\n",
    "과적합 규제(Regularization)\n",
    "표준 GBM 경우 과적합 규제기능이 없으나, XGBoost는 자체에 과적합 규제 기능으로 강한 내구성 지닌다.\n",
    "분류와 회귀영역에서 뛰어난 예측 성능 발휘\n",
    "즉, CART(Classification and regression tree) 앙상블 모델을 사용\n",
    "Early Stopping(조기 종료) 기능이 있음\n",
    "다양한 옵션을 제공하며 Customizing이 용이하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7181148748159057\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=30, learning_rate=0.05, max_depth=3, eval_metric='logloss', use_label_encoder =False)\n",
    "xgb.fit(x_train, y_train)\n",
    "pred = xgb.predict(x_test)\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
