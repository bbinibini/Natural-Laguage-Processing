{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문서 분류(Document Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비\n",
    "* 문서 분류에 필요한 데이터는 scikit-learn이 제공하는 20개의 주제를 가지는 뉴스그룹 데이터를 사용\n",
    "* 텍스트는 CounterVectorizer를 거쳐 DTM으로 변환\n",
    "* DTM은문서에 등장하는 단어들을 빈도 수 별로 표현한 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "news = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\",\n",
       " \"From: guykuo@carson.u.washington.edu (Guy Kuo)\\nSubject: SI Clock Poll - Final Call\\nSummary: Final call for SI clock reports\\nKeywords: SI,acceleration,clock,upgrade\\nArticle-I.D.: shelley.1qvfo9INNc3s\\nOrganization: University of Washington\\nLines: 11\\nNNTP-Posting-Host: carson.u.washington.edu\\n\\nA fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.\\n\\nGuy Kuo <guykuo@u.washington.edu>\\n\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7919, 130107) (7919,) (3395, 130107) (3395,)\n"
     ]
    }
   ],
   "source": [
    "x = news.data\n",
    "y = news.target\n",
    "\n",
    "cv = CountVectorizer()\n",
    "x = cv.fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3)\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 56979)\t2\n",
      "  (0, 85354)\t2\n",
      "  (0, 114688)\t1\n",
      "  (0, 111322)\t1\n",
      "  (0, 68532)\t1\n",
      "  (0, 114731)\t1\n",
      "  (0, 90379)\t1\n",
      "  (0, 76032)\t1\n",
      "  (0, 114579)\t1\n",
      "  (0, 114455)\t2\n",
      "  (0, 115475)\t1\n",
      "  (0, 32311)\t1\n",
      "  (0, 66608)\t3\n",
      "  (0, 27436)\t1\n",
      "  (0, 37565)\t1\n",
      "  (0, 128402)\t1\n",
      "  (0, 62221)\t1\n",
      "  (0, 29573)\t1\n",
      "  (0, 124616)\t1\n",
      "  (0, 28146)\t2\n",
      "  (0, 124332)\t1\n",
      "  (0, 26605)\t1\n",
      "  (0, 29620)\t1\n",
      "  (0, 80010)\t2\n",
      "  (0, 28012)\t1\n",
      "  :\t:\n",
      "  (0, 58500)\t1\n",
      "  (0, 49336)\t1\n",
      "  (0, 82571)\t1\n",
      "  (0, 111911)\t1\n",
      "  (0, 68157)\t1\n",
      "  (0, 81124)\t1\n",
      "  (0, 93463)\t1\n",
      "  (0, 72413)\t1\n",
      "  (0, 94913)\t1\n",
      "  (0, 22211)\t1\n",
      "  (0, 114804)\t1\n",
      "  (0, 81207)\t1\n",
      "  (0, 106554)\t1\n",
      "  (0, 77294)\t1\n",
      "  (0, 113650)\t2\n",
      "  (0, 70356)\t1\n",
      "  (0, 94583)\t1\n",
      "  (0, 83445)\t1\n",
      "  (0, 4745)\t1\n",
      "  (0, 19280)\t1\n",
      "  (0, 31460)\t1\n",
      "  (0, 125105)\t1\n",
      "  (0, 83641)\t1\n",
      "  (0, 32720)\t1\n",
      "  (0, 70068)\t1\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0]) #0번째 문서에서 , 56979 인덱스 단어가 2번 등장했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learn을 이용한 문서 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "* 이중분류모델\n",
    "* Logistic Regression은 특성상 다중 분류에는 적합하지 않음\n",
    "* 선형 회귀 모델에 시그모이드 함수를 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8966126656848307\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression(solver='liblinear')\n",
    "LR.fit(x_train, y_train)\n",
    "pred = LR.predict(x_test)\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines\n",
    "* 회귀, 분류, 이상치 탐지 등에 사용되는 지도학습 방법\n",
    "* 클래스 사이의 경계에 위치한 데이터 포인트를 서포트 벡터(support vector)라고 함\n",
    "* 각 서포트 벡터가 클래스 사이의 결정 경계를 구분하는데 얼마나 중요한지를 학습\n",
    "* 각 서포트 벡터 사이의 마진이 가장 큰 방향으로 학습\n",
    "* 서포트 벡터까지의 거리와 서포트 벡터의 중요도를 기반으로 예측을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8282768777614139\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "SVM = svm.SVC(kernel='linear')\n",
    "SVM.fit(x_train, y_train)\n",
    "\n",
    "pred = SVM.predict(x_test)\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classification\n",
    "* 베이즈 정리를 적용한 확률적 분류 알고리즘\n",
    "* 모든 특성들이 독립임을 가정(naive 가정)\n",
    "* 입력 특성에 따라 3개의 분류기 존재\n",
    "    * 가우시안 나이브 베이즈 분류기\n",
    "    * 베르누이 나이브 베이즈 분류기\n",
    "    * 다항 나이브 베이즈 분류기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문서 단어 행렬(Document-Term Matrix, DTM)을 이용한 나이브 베이즈\n",
    "* 다수의 문서에서 등장하는 각 단어들의 빈도를 행렬로 표현한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8244477172312223\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB = MultinomialNB()\n",
    "NB.fit(x_train, y_train)\n",
    "pred = NB.predict(x_test)\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf_idf를 이용한 정확도 향상 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TF-IDF(Term Frequency - Inverse Document Frequency)` 란?  \n",
    "* TF(단어 빈도, term frequency)는 특정한 단어가 문서 내에 얼마나 자주 등장하는지를 나타내는 값. \n",
    "* 이 값이 높을수록 문서에서 중요하다고 생각할 수 있다.\n",
    "* 하지만 하나의 문서에서 많이 나오지 않고 다른 문서에서 자주 등장하면 단어의 중요도는 낮아진다.\n",
    "* DF(문서 빈도, document frequency)라고 하며, 이 값의 역수를 IDF(역문서 빈도, inverse document frequency)라고 한다.\n",
    "* TF-IDF는 TF와 IDF를 곱한 값으로 점수가 높은 단어일수록 `다른 문서에는 많지 않고 해당 문서에서 자주 등장하는 단어`를 의미."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8332842415316642\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "x_train_tf = tfidf.fit_transform(x_train)\n",
    "x_test_tf = tfidf.fit_transform(x_test)\n",
    "\n",
    "NB.fit(x_train_tf, y_train)\n",
    "pred = NB.predict(x_test_tf)\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "* 분류나 회귀에 사용되는 지도 학습 방법\n",
    "* 데이터 특성으로부터 추론된 결정 `규칙`을 통해 값을 예측\n",
    "* if-then-else 결정 규칙을 통해 데이터 학습\n",
    "* 트리의 깊이가 깊을수록 복잡한 모델"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 스무고개 하듯이 예/아니오 질문을 이어가며 학습\n",
    "* 한번의 분기 때마다 변수 영역을 두 개로 구분합니다\n",
    "* 나뉜 각 범주에서 또 다시 데이터를 가장 잘 구분할 수 있는 질문을 기준으로 나눕니다. 이를 지나치게 많이 하면 오버피팅이 됩니다. 결정 트리에 아무 파라미터를 주지 않고 모델링하면 오버피팅이 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6382916053019145\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(x_train, y_train)\n",
    "pred = DT.predict(x_test)\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print(acc)\n",
    "# 현재 데이터로는 규칙을 찾기가 어려워서 정확도가 떨어짐.\n",
    "# 데이터 자체가 document, index라서. index만으로는 규칙을 찾기가 어려움.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "* XGBoost는 여러개의 Decision Tree를 조합해서 사용하는 Ensemble 알고리즘이다.\n",
    "* 분류에 있어서 다른 알고리즘보다 좋은 예측 성능을 보여줌  \n",
    " \n",
    "   \n",
    "* Boosting\n",
    "    * 약한 예측 모형들의 학습 에러에 가중치를 두고, 순차적으로 다음 학습 모델에 반영\n",
    "* Boosting 기법을 이용하여 구현한 알고리즘은 Gradient Boost 가 대표적인데\n",
    "* 이 알고리즘을 병렬 학습이 지원되도록 구현한 라이브러리가 XGBoost 이다.  \n",
    "\n",
    "\n",
    "* 장점\n",
    "    * GBM 대비 빠른 수행시간\n",
    "        * 병렬 처리로 학습, 분류 속도가 빠르다.\n",
    "\n",
    "    * 과적합 규제(Regularization)\n",
    "        * 표준 GBM 경우 과적합 규제기능이 없으나, XGBoost는 자체에 과적합 규제 기능으로 강한 내구성 지닌다.\n",
    "\n",
    "    * 분류와 회귀영역에서 뛰어난 예측 성능 발휘\n",
    "        * 즉, CART(Classification and regression tree) 앙상블 모델을 사용\n",
    "\n",
    "    * Early Stopping(조기 종료) 기능이 있음\n",
    "        * 다양한 옵션을 제공하며 Customizing이 용이하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7181148748159057\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=30, learning_rate=0.05, max_depth=3, eval_metric='logloss', use_label_encoder =False)\n",
    "xgb.fit(x_train, y_train)\n",
    "pred = xgb.predict(x_test)\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 교차 검증(Cross-Validation)\n",
    "* 일반 검증은 학습 데이터가 검증 데이터로 사용되지 않음\n",
    "    * 고정된 test set을 통해 모델의 성능을 검증하고 수정하는 과정을 반복하면, 결국 내가 만든 모델은 test set 에만 잘 동작하는 모델이 된다.\n",
    "    * 즉, test set에 과적합(overfitting)하게 되므로, 다른 실제 데이터를 가져와 예측을 수행하면 엉망인 결과가 나와버리게 된다.\n",
    "    \n",
    "    \n",
    "* train set + validation set으로 분리한 뒤, validation set을 사용해 검증하는 방식\n",
    "* 교차 검증은 데이터를 N개의 집합으로 나누어 정확도를 계산해 학습 데이터로 사용된 데이터도 테스트 데이터로 사용\n",
    "\n",
    "\n",
    "* 장점\n",
    "\n",
    "    * 모데이터셋을 훈련에 활용할 수 있다.\n",
    "        * 정확도를 향상시킬 수 있다.\n",
    "        * 데이터 부족으로 인한 underfitting을 방지할 수 있다.\n",
    "    \n",
    "    \n",
    "    * 모든 데이터셋을 평가에 활용할 수 있다.\n",
    "        * 평가에 사용되는 데이터 편중을 막을 수 있다.\n",
    "        * 평가 결과에 따라 좀 더 일반화된 모델을 만들 수 있다.\n",
    "\n",
    "* 단점\n",
    "    * Iteration 횟수가 많기 때문에, 모델 훈련/평가 시간이 오래 걸린다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나이브 베이즈모델을 교차 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83870968 0.83826779 0.82368537 0.83031374 0.83642794] 0.833480903927519\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(NB, x, y, cv=5)\n",
    "print(scores, scores.mean())"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정밀도(accuracy) 와 재현률(recall)\n",
    "\n",
    "* `정확도(accuracy) `\n",
    "    * 양성 클래스(정답)으로 예측한 샘플이 양성 클래스일 확률을 의미\n",
    "    * 모델이 얼마나 양성 클래스를 잘 예측하는지를 나타냄\n",
    "    \n",
    "    \n",
    "* `재현률(recall)`\n",
    "    * 양성 클래스인 샘플에서 모델이 양성 클래스로 예측한 샘플 비율을 의미하며, 모델이 얼마나 실제 상황을 재현하는지를 나타냄\n",
    "    * 항상 False라고 예측하는 모델은 accuracy가 높더라도 Recall이 0\n",
    "    * 항상 true라고 예측하는 모델은 accuracy가 낮더라도 Recall은 1\n",
    "    \n",
    "\n",
    "* `정밀도(Precision)`\n",
    "    * True로 예측한 데이터 중 실제로 True인 데이터의 수\n",
    "    * 항상 True로 예측하는 모델은 Recall이 1이지만, Precision은 낮음\n",
    "    * `Precision과 Recall은 서로 trade-off되는 관계가 있음`\n",
    "    \n",
    "    \n",
    "* `F1-score`\n",
    "    * precision 과 recall의 조화평균\n",
    "    * 정확도에 비해 더 효과적인 모델 분석 지표로 알려져 있음\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중 클래스 분류에서 F1 스코어 사용하기\n",
    "\n",
    "* 다중 클래스 분류 문제에서 정밀도와 재현률을 계산할 때는 클래스간의 지표를 어떻게 합칠지 지정 필요\n",
    "\n",
    "  * None - 클래스간 지표를 합치지 말고 그대로 출력\n",
    "  \n",
    "  \n",
    "  * micro - true positive와 false negative, false positive의 합을 산출해 스코어를 계산한다.\n",
    "      * 각 샘플이나 예측에 동일한 가중치를 부여하고자 할 때 사용한다.\n",
    "      * 정밀도와 재현률이 같음, 이로 인해 f1-score도 정밀도, 재현률과 동일\n",
    "      \n",
    "      \n",
    "  * macro - 각 레이블의 unweighted된 평균(레이블이 불균형한 멀티-클래스 분류 문제에서)을 계산한다. \n",
    "      * 레이블이 불균형을 따로 고려하지 않는다.\n",
    "      * 모든 클래스에 동일한 가중치를 부여하여 분류기의 전반적인 성능을 평가한다. \n",
    "      * 가장 빈도 높은 클래스 레이블의 성능이 중요하다.\n",
    "      \n",
    "      \n",
    "  * weighted - 클래스간 지표를 가중 평균한 값\n",
    "      * 각 레이블이 불균형해도, weight를 주어 평가지표를 계산한다. \n",
    "      * precision과 recall의 합이 아닌 F-score를 야기할 수 있다.\n",
    "      \n",
    "      \n",
    "  * samples\n",
    "      * 각 레이블의 평가지표를 평균 낸다.\n",
    "      * accuracy_score와 다른 멀티-레이블 분류 문제에서만 의미 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7181148748159057 0.7181148748159057 0.7181148748159056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "f1_param = 'micro'\n",
    "\n",
    "precision = precision_score(pred, y_test, average=f1_param)\n",
    "recall = recall_score(pred, y_test,average=f1_param)\n",
    "f1 = f1_score(pred, y_test,average =f1_param)\n",
    "\n",
    "print(precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7112683870442805 0.746715318917738 0.7218431021112164\n"
     ]
    }
   ],
   "source": [
    "f1_param = 'macro'\n",
    "\n",
    "precision = precision_score(pred, y_test, average=f1_param)\n",
    "recall = recall_score(pred, y_test,average=f1_param)\n",
    "f1 = f1_score(pred, y_test,average =f1_param)\n",
    "\n",
    "print(precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7237101048969392 0.7181148748159057 0.7107489856625017\n"
     ]
    }
   ],
   "source": [
    "f1_param = 'weighted'\n",
    "\n",
    "precision = precision_score(pred, y_test, average=f1_param)\n",
    "recall = recall_score(pred, y_test,average=f1_param)\n",
    "f1 = f1_score(pred, y_test,average =f1_param)\n",
    "\n",
    "print(precision, recall, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그리드 검색을 이용한 파라미터 최적화\n",
    "\n",
    "* 그리드 검색을 사용하면 분류기에 사용하는 파라미터 최적화 가능\n",
    "* 그리드 검색을 통해 앞서 구성한 나이브 베이즈 모델의 'alpha' 파라미터를 최적화시키는 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `estimator`: 사용 모델 객체     \n",
    "* `param_grid`: 사용 객체:지정 파라미터 리스트로 구성된 딕셔너리    \n",
    "* `scoring`: 최적화하고자 하는 성능 지표   \n",
    "* `cv`: 교차 검증 분할 개수      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=MultinomialNB(),\n",
       "             param_grid={'alpha': [1e-05, 0.0001, 0.0002, 0.0008]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "GS = GridSearchCV(estimator = NB, param_grid={'alpha' : [0.00001, 0.0001, 0.0002, 0.0008]}, scoring='accuracy', cv=10)\n",
    "GS.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8924339916206614\n",
      "{'alpha': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "print(GS.best_score_)\n",
    "print(GS.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
